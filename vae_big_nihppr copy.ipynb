{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu=7\n",
    "CUDA_VISIBLE_DEVICES=gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "11721506816\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "from random import shuffle\n",
    "\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score\n",
    "from sklearn.metrics import classification_report\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# import osa\n",
    "import shutil\n",
    "import seaborn as sns\n",
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from glob import glob\n",
    "from sklearn.metrics import roc_curve,auc, precision_score,precision_recall_curve,recall_score,precision_recall_fscore_support,confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import models\n",
    "from prettytable import PrettyTable\n",
    "print(torch.cuda.is_available())\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# import pandas as pd\n",
    "print(torch.cuda.get_device_properties(0).total_memory)\n",
    "print(torch.cuda.memory_allocated())\n",
    "gpu_id = gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.1+cu102'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install ray[tune]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv(\"/DATA/chowdari1/DATA/csv/ppr_nih_train.csv\")\n",
    "val_df=pd.read_csv(\"/DATA/chowdari1/DATA/csv/ppr_nih_val.csv\")\n",
    "test_df=pd.read_csv(\"/DATA/chowdari1/DATA/csv/ppr_nih_test.csv\")\n",
    "train_df=train_df.sample(frac=1,random_state=172)\n",
    "val_df=val_df.sample(frac=1,random_state=172)\n",
    "test_df=test_df.sample(frac=1,random_state=172)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Image index</th>\n",
       "      <th>target</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6421</th>\n",
       "      <td>6421</td>\n",
       "      <td>00019823_001.png</td>\n",
       "      <td>1</td>\n",
       "      <td>/DATA/chowdari1/DATA/dataset/nih/images_009/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5833</th>\n",
       "      <td>5833</td>\n",
       "      <td>00018194_000.png</td>\n",
       "      <td>0</td>\n",
       "      <td>/DATA/chowdari1/DATA/dataset/nih/images_008/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4382</th>\n",
       "      <td>4382</td>\n",
       "      <td>00014840_000.png</td>\n",
       "      <td>0</td>\n",
       "      <td>/DATA/chowdari1/DATA/dataset/nih/images_007/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>1977</td>\n",
       "      <td>00007292_003.png</td>\n",
       "      <td>1</td>\n",
       "      <td>/DATA/chowdari1/DATA/dataset/nih/images_004/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2409</th>\n",
       "      <td>2409</td>\n",
       "      <td>00009191_000.png</td>\n",
       "      <td>1</td>\n",
       "      <td>/DATA/chowdari1/DATA/dataset/nih/images_004/im...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0       Image index  target  \\\n",
       "6421        6421  00019823_001.png       1   \n",
       "5833        5833  00018194_000.png       0   \n",
       "4382        4382  00014840_000.png       0   \n",
       "1977        1977  00007292_003.png       1   \n",
       "2409        2409  00009191_000.png       1   \n",
       "\n",
       "                                                   path  \n",
       "6421  /DATA/chowdari1/DATA/dataset/nih/images_009/im...  \n",
       "5833  /DATA/chowdari1/DATA/dataset/nih/images_008/im...  \n",
       "4382  /DATA/chowdari1/DATA/dataset/nih/images_007/im...  \n",
       "1977  /DATA/chowdari1/DATA/dataset/nih/images_004/im...  \n",
       "2409  /DATA/chowdari1/DATA/dataset/nih/images_004/im...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for i in range(df.shape[0]):\n",
    "#     df['path'][i]+='.png'\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform,start,count):\n",
    "        self.ipaths = df[\"path\"][start:count].to_numpy()\n",
    "        self.target=df[\"target\"][start:count].to_numpy()\n",
    "        self.transform = transform\n",
    "        self.count=count\n",
    "        self.img_dir=img_dir\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path=self.img_dir+self.ipaths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label=self.target[idx]\n",
    "        image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.449,),(0.226,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8574, 4), (1706, 4))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir=''):\n",
    "    train_data=CustomImageDataset(train_df,'',transform,0,512)\n",
    "    valid_data=CustomImageDataset(val_df,'',transform,0,256)\n",
    "\n",
    "    return train_data, valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8448,1536\n",
    "# train_data=CustomImageDataset(train_df,'',transform,0,512)\n",
    "# valid_data=CustomImageDataset(val_df,'',transform,0,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data=CustomImageDataset(train_df,'',transform,0,8448)\n",
    "# valid_data=CustomImageDataset(val_df,'',transform,0,1536)\n",
    "# # test_data=CustomImageDataset(df,'/DATA/dataset/vinbig/vinbig/trainpng/',transform,7000+6000,df.shape[0])\n",
    "# print(len(train_data))\n",
    "# # print(len(test_data))\n",
    "# trainloader=torch.utils.data.DataLoader(train_data, batch_size=256)\n",
    "# valloader=torch.utils.data.DataLoader(valid_data, batch_size=256)\n",
    "# # testloader=torch.utils.data.DataLoader(test_data, batch_size=256)\n",
    "# print(trainloader)\n",
    "# # print(len(testloader))\n",
    "# # dataloaders = {\"train\":trainloader, \"val\":valloader, \"test\": testloader}\n",
    "# dataloaders = {\"train\":trainloader, \"val\":valloader}\n",
    "# # data_sizes = {x: len(dataloaders[x].sampler) for x in ['train','val','test']}\n",
    "# data_sizes = {x: len(dataloaders[x].sampler) for x in ['train','val']}\n",
    "\n",
    "# data_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU... Ready for HyperJump...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "device=torch.device(\"cuda:7\")\n",
    "print(\"Training on GPU... Ready for HyperJump...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(gpu_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalEncoder(nn.Module):\n",
    "    def __init__(self,l1=224,l2=4):\n",
    "        super(VariationalEncoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, 3, stride=2, padding=1)\n",
    "        # out_width = (28+2-5)/2+1 = 27/2+1 = 13\n",
    "        self.conv2 = nn.Conv2d(8,16, 3, stride=2, padding=1)\n",
    "        self.batch2 = nn.BatchNorm2d(16)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 3, stride=2, padding=0)\n",
    "        # out_width = (14-5)/2+1 = 5\n",
    "        #self.drop1=nn.Dropout2d(p=0.3) \n",
    "        # 6 * 6 * 16 = 576\n",
    "        latent_dims=l2\n",
    "        self.linear1 = nn.Linear(23328, l1)\n",
    "        self.linear2 = nn.Linear(l1, latent_dims)\n",
    "        self.linear3 = nn.Linear(l1, latent_dims)\n",
    "\n",
    "        self.N = torch.distributions.Normal(0, 1)\n",
    "        self.N.loc = self.N.loc.cuda() # hack to get sampling on the GPU\n",
    "        self.N.scale = self.N.scale.cuda()\n",
    "        self.kl = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        global en\n",
    "        x = x.to(device)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.batch2(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        #print(x.shape)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        mu =  self.linear2(x)\n",
    "        sigma = torch.exp(self.linear3(x))\n",
    "        z = mu + sigma*self.N.sample(mu.shape)\n",
    "        self.kl = (sigma**2 + mu**2 - torch.log(sigma) - 1/2).sum()\n",
    "        # print(en,'hello',z[0])\n",
    "        # en+=1\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self,l1=224,l2=4 ):\n",
    "        super().__init__()\n",
    "\n",
    "        ### Linear section\n",
    "        latent_dims=l2\n",
    "        self.decoder_lin = nn.Sequential(\n",
    "            # First linear layer\n",
    "            nn.Linear(latent_dims, l1),\n",
    "            nn.ReLU(True),\n",
    "            # Second linear layer\n",
    "            nn.Linear(l1, 23328),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        ### Unflatten\n",
    "        self.unflatten = nn.Unflatten(dim=1, unflattened_size=(32, 27, 27))\n",
    "\n",
    "        ### Convolutional section\n",
    "        self.decoder_conv = nn.Sequential(\n",
    "            # First transposed convolution\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, output_padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            # Second transposed convolution\n",
    "            nn.ConvTranspose2d(16, 8, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(True),\n",
    "            # Third transposed convolution\n",
    "            nn.ConvTranspose2d(8, 1, 3, stride=2, padding=1, output_padding=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        global de\n",
    "        # Apply linear layers\n",
    "        x = self.decoder_lin(x)\n",
    "        # print('de1',x)\n",
    "        # Unflatten\n",
    "        x = self.unflatten(x)\n",
    "        # print('de2',x)\n",
    "        # Apply transposed convolutions\n",
    "        x = self.decoder_conv(x)\n",
    "        # print('de3',x)\n",
    "        # Apply a sigmoid to force the output to be between 0 and 1 (valid pixel values)\n",
    "        x = torch.sigmoid(x)\n",
    "        # print(de,'de4',x[0][0][0][0])\n",
    "        # de+=1\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class VariationalAutoencoder(nn.Module):\n",
    "#     def __init__(self,l1=224,l2=4):\n",
    "#         super(VariationalAutoencoder, self).__init__()\n",
    "#         #  latent_dims\n",
    "#         # latent_dims=int(l2)\n",
    "#         self.encoder = VariationalEncoder(l1,l2)\n",
    "#         self.decoder = Decoder(l1,l2)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # x = x.to(device)\n",
    "#         z = self.encoder(x)\n",
    "#         # print(z)\n",
    "#         return self.decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoencoder(nn.Module,):\n",
    "    def __init__(self,l1=224,l2=4):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "        #  latent_dims\n",
    "        # latent_dims=int(l2)\n",
    "        # self.encoder = VariationalEncoder(l1,l2)\n",
    "        # self.decoder = Decoder(l1,l2)\n",
    "        self.l1=l1\n",
    "        self.l2=l2\n",
    "        # self.a=l1+l2\n",
    "        self.kl=0\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = x.to(device)\n",
    "        encoder = VariationalEncoder(self.l1,self.l2)\n",
    "        decoder = Decoder(self.l1,self.l2)\n",
    "        z=encoder(x)\n",
    "        self.kl=encoder.kl\n",
    "        return decoder(x)\n",
    "        # z = self.encoder(x)\n",
    "        # z=5+x.shape[0]\n",
    "        # z=self.a+1\n",
    "        # # print(z)\n",
    "        # # return self.decoder(z)\n",
    "        # return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device=torch.device(\"cuda:7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, l1=120, l2=84):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, l1)\n",
    "        self.fc2 = nn.Linear(l1, l2)\n",
    "        self.fc3 = nn.Linear(l2, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7f6da4679048>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae=VariationalAutoencoder(config['l1'],config['l2'])\n",
    "vae.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def train_mana(config):\n",
    "    vae=VariationalAutoencoder(config['l1'],config['l2'])\n",
    "    # net=Net(config['l1'],config['l2'])\n",
    "    # torch.cuda.empty_cache()\n",
    "    # device=torch.device(\"cuda:7\")\n",
    "    # vae.to(device)\n",
    "    optimizer = torch.optim.Adam(vae.parameters(), lr=config['lr'], weight_decay=1e-5)\n",
    "    trainset, testset= load_data()\n",
    "    trainloader=torch.utils.data.DataLoader(trainset, \n",
    "        batch_size=int(config[\"batch_size\"]))\n",
    "    valloader=torch.utils.data.DataLoader(testset, \n",
    "        batch_size=int(config[\"batch_size\"]))\n",
    "    \n",
    "    # for epoch in range(5):\n",
    "    # num_epochs=2\n",
    "    val_loss=0\n",
    "    # for epoch in tqdm.tqdm(range(num_epochs)):\n",
    "    # for epoch in range(num_epochs):\n",
    "        # # print('Epoch {}/{}'.format( epoch+1, num_epochs))       \n",
    "        # # print (datetime. datetime. now())\n",
    "        # # print('-' * 10)\n",
    "        # epoch_steps=0\n",
    "        # train_loss = 0.0\n",
    "        # # for x, _ in enumerate(trainloader,0):\n",
    "        # for x,_ in trainloader:\n",
    "        #     x=x.to(device)\n",
    "        #     x_hat=vae(x)\n",
    "        #     loss= ((x - x_hat)**2).sum() + vae.encoder.kl  \n",
    "\n",
    "        #     optimizer.zero_grad()\n",
    "        #     loss.backward()\n",
    "        #     optimizer.step()\n",
    "        #     train_loss=+loss.item()\n",
    "\n",
    "        #     epoch_steps+=1\n",
    "        # val_loss=0\n",
    "        # val_steps=0\n",
    "        # # for x,_ in enumerate(valloader,0):\n",
    "        # for x,_ in valloader:\n",
    "        #     with torch.no_grad():\n",
    "        #         x = x.to(device)\n",
    "        #         encoded_data = vae.encoder(x)\n",
    "        #         x_hat = vae(x)\n",
    "        #         loss = ((x - x_hat)**2).sum() + vae.encoder.kl\n",
    "        #         # val_loss += loss.item()\n",
    "        #         val_loss += loss.cpu().numpy()\n",
    "        #         val_steps+=1\n",
    "        # val_loss=val_loss / len(valloader.dataset)\n",
    "        # print(val_loss)\n",
    "        \n",
    "    y=intermediate(val_loss,config['l1'],config['l2'],config['batch_size'],config['lr'])\n",
    "    tune.report(score=y)\n",
    "    print(\"finished training ---------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intermediate(a,b,c,d,e):\n",
    "    score=a+b+c+d+e\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\n",
    "    'l1': 112,\n",
    "    'l2': 20,\n",
    "    'lr': 1e-3,\n",
    "    \"batch_size\": 256\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training ---------\n"
     ]
    }
   ],
   "source": [
    "train_mana(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\n",
    "    'l1': tune.grid_search([112,224]),\n",
    "    'l2': tune.grid_search([4,20]),\n",
    "    'lr':tune.choice([1e-3,1e-4]),\n",
    "    \"batch_size\" : tune.choice([256,256])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': {'grid_search': [112, 224]},\n",
       " 'l2': {'grid_search': [4, 20]},\n",
       " 'lr': <ray.tune.sample.Categorical at 0x7f3c407ace48>,\n",
       " 'batch_size': <ray.tune.sample.Categorical at 0x7f3c407ac128>}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': 112, 'l2': 4, 'lr': 0.001, 'batch_size': 256}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-09 13:01:17,660\tWARNING tune.py:580 -- Tune detects GPUs, but no trials are using GPUs. To enable trials to use GPUs, set tune.run(resources_per_trial={'gpu': 1}...) which allows Tune to expose 1 GPU to each trial. You can also override `Trainable.default_resource_request` if using the Trainable API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start-----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-09 13:01:20 (running for 00:00:02.57)<br>Memory usage on this node: 105.3/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/48 CPUs, 0/8 GPUs, 0.0/95.66 GiB heap, 0.0/44.99 GiB objects (0.0/1.0 accelerator_type:GTX)<br>Result logdir: /DATA/chowdari1/ray_results/train_mana_2022-02-09_13-01-17<br>Number of trials: 4/4 (3 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  l1</th><th style=\"text-align: right;\">  l2</th><th style=\"text-align: right;\">    lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_mana_44e0b_00000</td><td>RUNNING </td><td>172.25.0.208:44087</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\"> 112</td><td style=\"text-align: right;\">   4</td><td style=\"text-align: right;\">0.001 </td></tr>\n",
       "<tr><td>train_mana_44e0b_00001</td><td>PENDING </td><td>                  </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\"> 224</td><td style=\"text-align: right;\">   4</td><td style=\"text-align: right;\">0.001 </td></tr>\n",
       "<tr><td>train_mana_44e0b_00002</td><td>PENDING </td><td>                  </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\"> 112</td><td style=\"text-align: right;\">  20</td><td style=\"text-align: right;\">0.001 </td></tr>\n",
       "<tr><td>train_mana_44e0b_00003</td><td>PENDING </td><td>                  </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\"> 224</td><td style=\"text-align: right;\">  20</td><td style=\"text-align: right;\">0.0001</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m 2022-02-09 13:01:20,234\tERROR function_runner.py:268 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 262, in run\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m   File \"/tmp/ipykernel_30425/2091847976.py\", line 8, in train_mana\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/torch/optim/adam.py\", line 74, in __init__\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m     super(Adam, self).__init__(params, defaults)\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/torch/optim/optimizer.py\", line 49, in __init__\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m     raise ValueError(\"optimizer got an empty parameter list\")\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m ValueError: optimizer got an empty parameter list\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m Exception in thread Thread-2:\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m   File \"/usr/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 281, in run\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 262, in run\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m   File \"/tmp/ipykernel_30425/2091847976.py\", line 8, in train_mana\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/torch/optim/adam.py\", line 74, in __init__\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m     super(Adam, self).__init__(params, defaults)\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/torch/optim/optimizer.py\", line 49, in __init__\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m     raise ValueError(\"optimizer got an empty parameter list\")\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m ValueError: optimizer got an empty parameter list\n",
      "\u001b[2m\u001b[36m(train_mana pid=44087)\u001b[0m \n",
      "2022-02-09 13:01:20,442\tERROR trial_runner.py:927 -- Trial train_mana_44e0b_00000: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 893, in _process_trial\n",
      "    results = self.trial_executor.fetch_result(trial)\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 707, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/worker.py\", line 1733, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=44087, ip=172.25.0.208, repr=train_mana)\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/trainable.py\", line 315, in train\n",
      "    result = self.step()\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 381, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 532, in _report_thread_runner_error\n",
      "    (\"Trial raised an exception. Traceback:\\n{}\".format(err_tb_str)\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=44087, ip=172.25.0.208, repr=train_mana)\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 262, in run\n",
      "    self._entrypoint()\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
      "    self._status_reporter.get_checkpoint())\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_30425/2091847976.py\", line 8, in train_mana\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/torch/optim/adam.py\", line 74, in __init__\n",
      "    super(Adam, self).__init__(params, defaults)\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/torch/optim/optimizer.py\", line 49, in __init__\n",
      "    raise ValueError(\"optimizer got an empty parameter list\")\n",
      "ValueError: optimizer got an empty parameter list\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_mana_44e0b_00000:\n",
      "  date: 2022-02-09_13-01-20\n",
      "  experiment_id: 73ace2e347a44308b8c2928e20a0da3d\n",
      "  hostname: BOSS8-OS\n",
      "  node_ip: 172.25.0.208\n",
      "  pid: 44087\n",
      "  timestamp: 1644391880\n",
      "  trial_id: 44e0b_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m 2022-02-09 13:01:22,245\tERROR function_runner.py:268 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 262, in run\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m   File \"/tmp/ipykernel_30425/2091847976.py\", line 8, in train_mana\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/torch/optim/adam.py\", line 74, in __init__\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m     super(Adam, self).__init__(params, defaults)\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/torch/optim/optimizer.py\", line 49, in __init__\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m     raise ValueError(\"optimizer got an empty parameter list\")\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m ValueError: optimizer got an empty parameter list\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m Exception in thread Thread-2:\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m   File \"/usr/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 281, in run\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 262, in run\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m   File \"/tmp/ipykernel_30425/2091847976.py\", line 8, in train_mana\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/torch/optim/adam.py\", line 74, in __init__\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m     super(Adam, self).__init__(params, defaults)\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/torch/optim/optimizer.py\", line 49, in __init__\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m     raise ValueError(\"optimizer got an empty parameter list\")\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m ValueError: optimizer got an empty parameter list\n",
      "\u001b[2m\u001b[36m(train_mana pid=44275)\u001b[0m \n",
      "2022-02-09 13:01:22,315\tERROR trial_runner.py:927 -- Trial train_mana_44e0b_00002: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 893, in _process_trial\n",
      "    results = self.trial_executor.fetch_result(trial)\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 707, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/worker.py\", line 1733, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=44260, ip=172.25.0.208, repr=train_mana)\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/trainable.py\", line 315, in train\n",
      "    result = self.step()\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 381, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 532, in _report_thread_runner_error\n",
      "    (\"Trial raised an exception. Traceback:\\n{}\".format(err_tb_str)\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=44260, ip=172.25.0.208, repr=train_mana)\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 262, in run\n",
      "    self._entrypoint()\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
      "    self._status_reporter.get_checkpoint())\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_30425/2091847976.py\", line 8, in train_mana\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/torch/optim/adam.py\", line 74, in __init__\n",
      "    super(Adam, self).__init__(params, defaults)\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/torch/optim/optimizer.py\", line 49, in __init__\n",
      "    raise ValueError(\"optimizer got an empty parameter list\")\n",
      "ValueError: optimizer got an empty parameter list\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m 2022-02-09 13:01:22,397\tERROR function_runner.py:268 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 262, in run\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m   File \"/tmp/ipykernel_30425/2091847976.py\", line 8, in train_mana\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/torch/optim/adam.py\", line 74, in __init__\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m     super(Adam, self).__init__(params, defaults)\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/torch/optim/optimizer.py\", line 49, in __init__\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m     raise ValueError(\"optimizer got an empty parameter list\")\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m ValueError: optimizer got an empty parameter list\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m Exception in thread Thread-2:\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m   File \"/usr/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 281, in run\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 262, in run\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m   File \"/tmp/ipykernel_30425/2091847976.py\", line 8, in train_mana\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/torch/optim/adam.py\", line 74, in __init__\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m     super(Adam, self).__init__(params, defaults)\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/torch/optim/optimizer.py\", line 49, in __init__\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m     raise ValueError(\"optimizer got an empty parameter list\")\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m ValueError: optimizer got an empty parameter list\n",
      "\u001b[2m\u001b[36m(train_mana pid=44239)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m 2022-02-09 13:01:22,308\tERROR function_runner.py:268 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 262, in run\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m   File \"/tmp/ipykernel_30425/2091847976.py\", line 8, in train_mana\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/torch/optim/adam.py\", line 74, in __init__\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m     super(Adam, self).__init__(params, defaults)\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/torch/optim/optimizer.py\", line 49, in __init__\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m     raise ValueError(\"optimizer got an empty parameter list\")\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m ValueError: optimizer got an empty parameter list\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m Exception in thread Thread-2:\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m   File \"/usr/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 281, in run\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 262, in run\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m   File \"/tmp/ipykernel_30425/2091847976.py\", line 8, in train_mana\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/torch/optim/adam.py\", line 74, in __init__\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m     super(Adam, self).__init__(params, defaults)\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m   File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/torch/optim/optimizer.py\", line 49, in __init__\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m     raise ValueError(\"optimizer got an empty parameter list\")\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m ValueError: optimizer got an empty parameter list\n",
      "\u001b[2m\u001b[36m(train_mana pid=44260)\u001b[0m \n",
      "2022-02-09 13:01:22,450\tERROR trial_runner.py:927 -- Trial train_mana_44e0b_00001: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 893, in _process_trial\n",
      "    results = self.trial_executor.fetch_result(trial)\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 707, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/worker.py\", line 1733, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=44275, ip=172.25.0.208, repr=train_mana)\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/trainable.py\", line 315, in train\n",
      "    result = self.step()\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 381, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 532, in _report_thread_runner_error\n",
      "    (\"Trial raised an exception. Traceback:\\n{}\".format(err_tb_str)\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=44275, ip=172.25.0.208, repr=train_mana)\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 262, in run\n",
      "    self._entrypoint()\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
      "    self._status_reporter.get_checkpoint())\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_30425/2091847976.py\", line 8, in train_mana\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/torch/optim/adam.py\", line 74, in __init__\n",
      "    super(Adam, self).__init__(params, defaults)\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/torch/optim/optimizer.py\", line 49, in __init__\n",
      "    raise ValueError(\"optimizer got an empty parameter list\")\n",
      "ValueError: optimizer got an empty parameter list\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_mana_44e0b_00002:\n",
      "  date: 2022-02-09_13-01-22\n",
      "  experiment_id: c2a56b41fd13464684b44a70c04ac068\n",
      "  hostname: BOSS8-OS\n",
      "  node_ip: 172.25.0.208\n",
      "  pid: 44260\n",
      "  timestamp: 1644391882\n",
      "  trial_id: 44e0b_00002\n",
      "  \n",
      "Result for train_mana_44e0b_00001:\n",
      "  date: 2022-02-09_13-01-22\n",
      "  experiment_id: 7d9aaa88921f494dacbe7036449207f6\n",
      "  hostname: BOSS8-OS\n",
      "  node_ip: 172.25.0.208\n",
      "  pid: 44275\n",
      "  timestamp: 1644391882\n",
      "  trial_id: 44e0b_00001\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-09 13:01:22,603\tERROR trial_runner.py:927 -- Trial train_mana_44e0b_00003: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 893, in _process_trial\n",
      "    results = self.trial_executor.fetch_result(trial)\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 707, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/worker.py\", line 1733, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=44239, ip=172.25.0.208, repr=train_mana)\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/trainable.py\", line 315, in train\n",
      "    result = self.step()\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 381, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 532, in _report_thread_runner_error\n",
      "    (\"Trial raised an exception. Traceback:\\n{}\".format(err_tb_str)\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=44239, ip=172.25.0.208, repr=train_mana)\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 262, in run\n",
      "    self._entrypoint()\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
      "    self._status_reporter.get_checkpoint())\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_30425/2091847976.py\", line 8, in train_mana\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/torch/optim/adam.py\", line 74, in __init__\n",
      "    super(Adam, self).__init__(params, defaults)\n",
      "  File \"/DATA/chowdari1/.local/lib/python3.7/site-packages/torch/optim/optimizer.py\", line 49, in __init__\n",
      "    raise ValueError(\"optimizer got an empty parameter list\")\n",
      "ValueError: optimizer got an empty parameter list\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_mana_44e0b_00003:\n",
      "  date: 2022-02-09_13-01-22\n",
      "  experiment_id: 632980fea8a44e5391a6b948c12a9e72\n",
      "  hostname: BOSS8-OS\n",
      "  node_ip: 172.25.0.208\n",
      "  pid: 44239\n",
      "  timestamp: 1644391882\n",
      "  trial_id: 44e0b_00003\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-09 13:01:22 (running for 00:00:04.98)<br>Memory usage on this node: 105.2/251.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/48 CPUs, 0/8 GPUs, 0.0/95.66 GiB heap, 0.0/44.99 GiB objects (0.0/1.0 accelerator_type:GTX)<br>Result logdir: /DATA/chowdari1/ray_results/train_mana_2022-02-09_13-01-17<br>Number of trials: 4/4 (4 ERROR)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  l1</th><th style=\"text-align: right;\">  l2</th><th style=\"text-align: right;\">    lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_mana_44e0b_00000</td><td>ERROR   </td><td>172.25.0.208:44087</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\"> 112</td><td style=\"text-align: right;\">   4</td><td style=\"text-align: right;\">0.001 </td></tr>\n",
       "<tr><td>train_mana_44e0b_00001</td><td>ERROR   </td><td>172.25.0.208:44275</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\"> 224</td><td style=\"text-align: right;\">   4</td><td style=\"text-align: right;\">0.001 </td></tr>\n",
       "<tr><td>train_mana_44e0b_00002</td><td>ERROR   </td><td>172.25.0.208:44260</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\"> 112</td><td style=\"text-align: right;\">  20</td><td style=\"text-align: right;\">0.001 </td></tr>\n",
       "<tr><td>train_mana_44e0b_00003</td><td>ERROR   </td><td>172.25.0.208:44239</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\"> 224</td><td style=\"text-align: right;\">  20</td><td style=\"text-align: right;\">0.0001</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 4<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                             </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_mana_44e0b_00000</td><td style=\"text-align: right;\">           1</td><td>/DATA/chowdari1/ray_results/train_mana_2022-02-09_13-01-17/train_mana_44e0b_00000_0_batch_size=256,l1=112,l2=4,lr=0.001_2022-02-09_13-01-17/error.txt  </td></tr>\n",
       "<tr><td>train_mana_44e0b_00001</td><td style=\"text-align: right;\">           1</td><td>/DATA/chowdari1/ray_results/train_mana_2022-02-09_13-01-17/train_mana_44e0b_00001_1_batch_size=256,l1=224,l2=4,lr=0.001_2022-02-09_13-01-20/error.txt  </td></tr>\n",
       "<tr><td>train_mana_44e0b_00002</td><td style=\"text-align: right;\">           1</td><td>/DATA/chowdari1/ray_results/train_mana_2022-02-09_13-01-17/train_mana_44e0b_00002_2_batch_size=256,l1=112,l2=20,lr=0.001_2022-02-09_13-01-20/error.txt </td></tr>\n",
       "<tr><td>train_mana_44e0b_00003</td><td style=\"text-align: right;\">           1</td><td>/DATA/chowdari1/ray_results/train_mana_2022-02-09_13-01-17/train_mana_44e0b_00003_3_batch_size=256,l1=224,l2=20,lr=0.0001_2022-02-09_13-01-20/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [train_mana_44e0b_00000, train_mana_44e0b_00001, train_mana_44e0b_00002, train_mana_44e0b_00003])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30425/4274725785.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m analysis = tune.run(\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_mana\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0manalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"min\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, max_concurrent_trials, queue_trials, loggers, _remote)\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGINT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [train_mana_44e0b_00000, train_mana_44e0b_00001, train_mana_44e0b_00002, train_mana_44e0b_00003])"
     ]
    }
   ],
   "source": [
    "print('start-----')\n",
    "analysis = tune.run(\n",
    "    train_mana,\n",
    "    config=config\n",
    ")\n",
    "s=analysis.get_best_config(metric=\"score\", mode=\"min\")\n",
    "print(\"best config: \", analysis.get_best_config(metric=\"score\", mode=\"max\"))\n",
    "# df = analysis.dataframe(metric=\"score\", mode=\"min\")\n",
    "# all_dataframes = analysis.trial_dataframes\n",
    "print('heloo------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def train(config,checkpoint_dir=None,data_dir=None):\n",
    "    vae=VariationalAutoencoder(config['l1'],config['l2'])\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    device=torch.device(\"cuda:7\")\n",
    "\n",
    "    vae.to(device)\n",
    "    optimizer = torch.optim.Adam(vae.parameters(), lr=config['lr'], weight_decay=1e-5)\n",
    "\n",
    "    if checkpoint_dir:\n",
    "        model_state, optimizer_state=torch.load(\n",
    "            os.path.join(checkpoint_dir,\"checkpoint\"))\n",
    "        vae.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    trainset, testset= load_data(data_dir)\n",
    "    trainloader=torch.utils.data.DataLoader(trainset, \n",
    "        batch_size=int(config[\"batch_size\"]), num_workers=8)\n",
    "    valloader=torch.utils.data.DataLoader(testset, \n",
    "        batch_size=int(config[\"batch_size\"]), num_workers=8)\n",
    "\n",
    "    for epoch in range(10):\n",
    "        print('Epoch {}/{}'.format( epoch+1, num_epochs))       \n",
    "        print (datetime. datetime. now())\n",
    "        print('-' * 10)\n",
    "        epoch_steps=0\n",
    "        train_loss = 0.0\n",
    "        for x, _ in enumerate(trainloader,0):\n",
    "            x=x.to(device)\n",
    "            x_hat=vae(x)\n",
    "            loss= ((x - x_hat)**2).sum() + vae.encoder.kl  \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss=+loss.item()\n",
    "\n",
    "            epoch_steps+=1\n",
    "        val_loss=0\n",
    "        val_steps=0\n",
    "        for x,_ in enumerate(valloader,0):\n",
    "            with torch.no_grad():\n",
    "                x = x.to(device)\n",
    "                encoded_data = vae.encoder(x)\n",
    "                x_hat = vae(x)\n",
    "                loss = ((x - x_hat)**2).sum() + vae.encoder.kl\n",
    "                # val_loss += loss.item()\n",
    "                val_loss += loss.cpu().numpy()\n",
    "                val_steps+=1\n",
    "        \n",
    "        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "            path=os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "            torch.save((vae.state_dict(), optimizer.state_dict()),path)\n",
    "        \n",
    "        tune.report(loss=(train_loss / len(trainloader.dataset)), accuracy=(val_loss / len(valloader.dataset)))\n",
    "    print(\"finished training\")\n",
    "                \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(vae, device=device):\n",
    "    trainset, testset=load_data()\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "    \n",
    "    val_loss=0\n",
    "    with torch.no_grad():\n",
    "        for x,_ in enumerate(testloader,0):\n",
    "            with torch.no_grad():\n",
    "                x = x.to(device)\n",
    "                encoded_data = vae.encoder(x)\n",
    "                x_hat = vae(x)\n",
    "                loss = ((x - x_hat)**2).sum() + vae.encoder.kl\n",
    "                # val_loss += loss.item()\n",
    "                val_loss += loss.cpu().numpy()\n",
    "                # val_steps+=1\n",
    "    return  (val_loss / len(testloader.dataset))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functools import partial\n",
    "# config={\n",
    "#         \"l1\": 224,\n",
    "#         \"l2\": tune.choice([4,20]),\n",
    "#         \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "#         \"lr\": tune.choice([1e-4, 1e-1]),\n",
    "#         \"batch_size\": 256\n",
    "#     }\n",
    "# result = tune.run(\n",
    "#         partial(train, data_dir=''),     \n",
    "#         config=config,\n",
    "#         # resources_per_trail={'gpu': 1},\n",
    "#         # resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trail}\n",
    "#         )\n",
    "# print(\"Best config: \", result.get_best_config(metric=\"mean_accuracy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "def main(num_samples=10, max_num_epochs=10, gpus_per_trail=2):\n",
    "    data_dir=''\n",
    "    load_data('')\n",
    "    config={\n",
    "        \"l1\": tune.choice([224]),\n",
    "        \"l2\": tune.choice([4,20]),\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "        \"batch_size\": tune.choice([256])\n",
    "    }\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2)\n",
    "    reporter = CLIReporter(\n",
    "        # parameter_columns=[\"l1\", \"l2\", \"lr\", \"batch_size\"],\n",
    "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
    "    result = tune.run(\n",
    "        partial(train, data_dir=data_dir),\n",
    "        resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trail},\n",
    "        config=config,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        progress_reporter=reporter)\n",
    "    \n",
    "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_trial.last_result[\"loss\"]))\n",
    "    print(\"Best trial final validation accuracy: {}\".format(\n",
    "        best_trial.last_result[\"accuracy\"]))\n",
    "    \n",
    "    best_trained_model = VariationalAutoencoder(best_trial.config[\"l1\"], best_trial.config[\"l2\"])\n",
    "    best_trained_model.to(device)\n",
    "\n",
    "    best_checkpoint_dir = best_trial.checkpoint.value\n",
    "    model_state, optimizer_state = torch.load(os.path.join(\n",
    "        best_checkpoint_dir, \"checkpoint\"))\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "    test_acc = test_accuracy(best_trained_model, device)\n",
    "    print(\"Best trial test set accuracy: {}\".format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main(num_samples=10, max_num_epochs=10, gpus_per_trail=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(vae, device, dataloader, optimizer):\n",
    "    # Set train mode for both the encoder and the decoder\n",
    "    vae.train()\n",
    "    train_loss = 0.0\n",
    "    phase='train'\n",
    "    # Iterate the dataloader (we do not need the label values, this is unsupervised learning)\n",
    "    # for x, _ in dataloader: \n",
    "    for x, _ in tqdm.tqdm(dataloader, desc=phase, leave=False):\n",
    "        # Move tensor to the proper device\n",
    "        x = x.to(device)\n",
    "        x_hat = vae(x)\n",
    "        # Evaluate loss\n",
    "        loss = ((x - x_hat)**2).sum() + vae.encoder.kl\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Print batch loss\n",
    "        # print('\\t partial train loss (single batch): %f' % (loss.item()))\n",
    "        train_loss+=loss.item()\n",
    "\n",
    "    return train_loss / len(dataloader.dataset), vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(vae, device, dataloader):\n",
    "    # Set evaluation mode for encoder and decoder\n",
    "    vae.eval()\n",
    "    val_loss = 0.0\n",
    "    phase='test'\n",
    "    with torch.no_grad(): # No need to track the gradients\n",
    "        for x, _ in tqdm.tqdm(dataloader, desc=phase, leave=False):\n",
    "            # Move tensor to the proper device\n",
    "            x = x.to(device)\n",
    "            # Encode data\n",
    "            encoded_data = vae.encoder(x)\n",
    "            # Decode data\n",
    "            x_hat = vae(x)\n",
    "            loss = ((x - x_hat)**2).sum() + vae.encoder.kl\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    return val_loss / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1280\n",
    "test_data=CustomImageDataset(test_df,'',transform,0,256)\n",
    "testloader=torch.utils.data.DataLoader(test_data, batch_size=256)\n",
    "len(testloader.sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data=CustomImageDataset(test_df,'',transform,0,1280)\n",
    "# testloader=torch.utils.data.DataLoader(test_data, batch_size=256)\n",
    "# len(testloader.sampler)\n",
    "def test_loss(vae, device, dataloader):\n",
    "    # Set evaluation mode for encoder and decoder\n",
    "    vae.eval()\n",
    "    val_loss = 0.0\n",
    "    phase='test'\n",
    "    with torch.no_grad(): # No need to track the gradients\n",
    "        for x, _ in tqdm.tqdm(dataloader, desc=phase, leave=False):\n",
    "            # Move tensor to the proper device\n",
    "            x = x.to(device)\n",
    "            # Encode data\n",
    "            encoded_data = vae.encoder(x)\n",
    "            # Decode data\n",
    "            x_hat = vae(x)\n",
    "            loss = ((x - x_hat)**2).sum() + vae.encoder.kl\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    return val_loss / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset=CustomImageDataset(test_df,'',transform,0,256)\n",
    "def plot_ae_outputs(encoder,decoder,n=5):\n",
    "    plt.figure(figsize=(10,4.5))\n",
    "    for i in range(n):\n",
    "      ax = plt.subplot(2,n,i+1)\n",
    "      img = test_dataset[i][0].unsqueeze(0).to(device)\n",
    "      encoder.eval()\n",
    "      decoder.eval()\n",
    "      with torch.no_grad():\n",
    "         rec_img  = decoder(encoder(img))\n",
    "      plt.imshow(img.cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "      ax.get_xaxis().set_visible(False)\n",
    "      ax.get_yaxis().set_visible(False)  \n",
    "      if i == n//2:\n",
    "        ax.set_title('Original images')\n",
    "      ax = plt.subplot(2, n, i + 1 + n)\n",
    "      plt.imshow(rec_img.cpu().squeeze().numpy(), cmap='gist_gray')  \n",
    "      plt.imshow(rec_img.cpu().squeeze().numpy(), cmap='gist_gray')  \n",
    "      ax.get_xaxis().set_visible(False)\n",
    "      ax.get_yaxis().set_visible(False)  \n",
    "      if i == n//2:\n",
    "         ax.set_title('Reconstructed images')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "num_epochs=3\n",
    "dims=4\n",
    "learn_rt=1e-3\n",
    "def train(config,checkpoint_dir=None, data_dir=None):\n",
    "    # vae=VariationalAutoencoder(latent_dims=config['latent_dim'])\n",
    "    vae=VariationalAutoencoder(latent_dims=dims)\n",
    "    # optim = torch.optim.Adam(vae.parameters(), lr=config['lr'], weight_decay=1e-5)\n",
    "    optim = torch.optim.Adam(vae.parameters(), lr=learn_rt, weight_decay=1e-5)\n",
    "    if checkpoint_dir:\n",
    "        model_state, optimizer_state= torch.load(\n",
    "            os.path.join(checkpoint_dir,\"checkpoint\"))\n",
    "        vae.load_state_dict(model_state)\n",
    "        optim.load_state_dict(optimizer_state)\n",
    "\n",
    "    trainloader=torch.utils.data.DataLoader(train_data, batch_size=256)\n",
    "    valloader=torch.utils.data.DataLoader(valid_data, batch_size=256)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format( epoch+1, num_epochs))       \n",
    "        print (datetime. datetime. now())\n",
    "        print('-' * 10)\n",
    "        train_loss,vae = train_epoch(vae,device,trainloader,optim)\n",
    "        val_loss = test_epoch(vae,device,valloader)\n",
    "\n",
    "        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "            path=os.path.join(checkpoint_dir,'checkpoint')\n",
    "            torch.save((vae.state_dict(),optim.state_dict(),path))\n",
    "        \n",
    "        tune.report(loss=val_loss, accuracy= train_loss)\n",
    "    print(\"training over\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/DATA/chowdari1/vae/checkpoint'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path= os.path.join('/DATA/chowdari1/vae', \"checkpoint\")\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "# max_num_epoch=100\n",
    "\n",
    "def main(max_num_epochs):\n",
    "        print('num_epochs: ',max_num_epochs)\n",
    "        config={\n",
    "        \"latent_dim\": tune.choice([2,4,8,20]),\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "        \"batch_size\": tune.choice([256,64])\n",
    "        }\n",
    "        scheduler = ASHAScheduler(\n",
    "                metric=\"loss\",\n",
    "                mode=\"min\",\n",
    "                max_t=max_num_epochs,\n",
    "                grace_period=1,\n",
    "                reduction_factor=2)\n",
    "        # reporter = CLIReporter()\n",
    "                # parameter_columns=[\"l1\", \"l2\", \"lr\", \"batch_size\"],\n",
    "                # metric_columns=[\"loss\", \"accuracy\",\"training_iteration\"])\n",
    "        # num_epochs,config,checkpoint_dir=None, data_dir=None\n",
    "        result = tune.run(\n",
    "        partial(train ), \n",
    "         resources_per_trial={\"cpu\": 2, \"gpu\": 0},       \n",
    "        config=config,\n",
    "        scheduler=scheduler,\n",
    "        # progress_reporter=reporter\n",
    "        )\n",
    "\n",
    "        best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "        print(\"Best trial config: {}\".format(best_trial.config))\n",
    "        print(\"Best trial final validation loss: {}\".format(\n",
    "        best_trial.last_result[\"loss\"]))\n",
    "        print(\"Best trial final validation accuracy: {}\".format(\n",
    "        best_trial.last_result[\"accuracy\"]))\n",
    "\n",
    "        best_trained_model = VariationalAutoencoder(latent_dims=best_trail.config['latent_dim'])\n",
    "\n",
    "        best_checkpoint_dir = best_trial.checkpoint.value\n",
    "        model_state, optimizer_state = torch.load(os.path.join(\n",
    "                best_checkpoint_dir, \"checkpoint\"))\n",
    "        best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "        test_acc = test_loss(best_trained_model, device,testloader)\n",
    "        print(\"Best trial test set accuracy: {}\".format(test_acc))\n",
    "\n",
    "# if __name__ =='main':\n",
    "#         print('noooo')\n",
    "#         main(5)\n",
    "#         print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ =='__main__':\n",
    "    main(3)\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ =='__main__':\n",
    "    main(3)\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs = 10\n",
    "import datetime\n",
    "def train(vae,num_epochs):\n",
    "    best_test_loss = float('inf')\n",
    "    best_model_wts = copy.deepcopy(vae.state_dict())\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format( epoch+1, num_epochs))       \n",
    "        print (datetime. datetime. now())\n",
    "        print('-' * 10)\n",
    "        train_loss = train_epoch(vae,device,trainloader,optim)\n",
    "        val_loss = test_epoch(vae,device,valloader)\n",
    "        if(best_test_loss > val_loss):\n",
    "            best_test_loss=val_loss\n",
    "            best_model_wts = copy.deepcopy(vae.state_dict())\n",
    "        print('\\n EPOCH {}/{} \\t train loss {:.3f} \\t val loss {:.3f}'.format(epoch + 1, num_epochs,train_loss,val_loss))\n",
    "    print('best_test_loss: ',best_test_loss)\n",
    "    plot_ae_outputs(vae.encoder,vae.decoder,n=5)\n",
    "\n",
    "    vae.load_state_dict(best_model_wts)\n",
    "    return vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "va=train(vae,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "   train_loss = train_epoch(vae,device,trainloader,optim)\n",
    "   val_loss = test_epoch(vae,device,valloader)\n",
    "   print('\\n EPOCH {}/{} \\t train loss {:.3f} \\t val loss {:.3f}'.format(epoch + 1, num_epochs,train_loss,val_loss))\n",
    "\n",
    "plot_ae_outputs(vae.encoder,vae.decoder,n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/DATA/radhasyam1/saved_models/vae.pth\"\n",
    "torch.save(vae.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/DATA/chowdari1/saved_models/vae/vae_big_nihppr_100ep.pth\n"
     ]
    }
   ],
   "source": [
    "path='/DATA/chowdari1/saved_models/vae/vae_big_nihppr_100ep.pth'\n",
    "# model=densenet_Model(pretrained=True)\n",
    "model= VariationalAutoencoder(latent_dims=d)\n",
    "x_model=torch.load(path,map_location='cpu')\n",
    "# x_model=x_model.to(device)\n",
    "model.load_state_dict(x_model)\n",
    "model=model.to(device)\n",
    "model.eval()\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8b70d09a34a48409f89c8b0c61f9191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='test'), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "21651.47109375"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss = test_epoch(model,device,testloader)\n",
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ae_outputs(model.encoder,model.decoder,n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4beda4614f54301935dcfa0963c4faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='test'), FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "36669.517578125"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss = test_epoch(va,device,testloader)\n",
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1344, 4)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=CustomImageDataset(test_df,'',transform,0,1280)\n",
    "testloader=torch.utils.data.DataLoader(test_data, batch_size=256)\n",
    "len(testloader.sampler)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
